{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About","text":"<p>Hi!, I'm Andres, nice to meet you! \ud83d\udc4b</p> <p>         I'm a Python Developer \ud83d\udc0d from Colombia \ud83c\udde8\ud83c\uddf4.         I am currently living in Portim\u00e3o, Portugal \ud83c\uddf5\ud83c\uddf9.     </p> Facts about me: <ul> <li> I have a degree in Civil Engineering. \ud83d\udc77</li> <li> I first got into programming with Visual Basic for Applications (VBA). \ud83d\udcca</li> <li> I started with Python \ud83d\udc0d in 2018 as part of the \"Geolog\u00eda Matem\u00e1tica y Computacional\" Research Group at the National University of Colombia. \ud83d\udcbb</li> <li> <p> I am auhor &amp; co-author of two publications in the engineering field \u26f0\ufe0f</p> <ul> <li> <p>Ariza-Triana, A., Montoya-Araque, E. A., &amp; Suarez-Burgoa, L. O. (2021). Modeling of Bimrock/Bimsoil Structures by Means of Circular Particles Packed in R2. In M. Barla, A. Di Donna, &amp; D. Sterpi (Eds.), Lecture Notes in Civil Engineering (Vol. 126, pp. 737\u2013743). Springer International Publishing. DOI: 10.1007/978-3-030-64518-2_87.</p> </li> <li> <p>Suarez-Burgoa, L. O., Ariza-Triana, A., &amp; Montoya-Araque, E. (2019). Modelamiento de estructuras de bimsoils mediante el empaquetado de part\u00edculas circulares en R2. Revista de La Facultad de Ciencias, 8(2), 115\u2013137. DOI: 10.15446/rev.fac.cienc.v8n2.72343.</p> </li> </ul> </li> <li> <p> I am interested in Python stuff but I've been learning Rust \ud83e\udd80 lately, just for fun.</p> </li> <li> I created this blog just to share some content related to Python, I hope you can learn something from it \ud83d\ude01.</li> </ul>"},{"location":"posts/context_managers_usage/","title":"Useful Applications of Python Context Managers.","text":"<p>As everyone could know, Python Context Managers are a type of object that we can use in a <code>with</code> block. What it does is to execute some clean up code after exiting from <code>with</code> block. it's mostly used to make sure to free up resources when a exception occurs inside a <code>with</code> block.</p> <p>You could be familiar with this example: <pre><code>with open('my_file.ext', 'rw') as file:\n# proccess file\nassert file == file.closed # True\n</code></pre></p> <p>the above snippet of code opens a file and then make some operations in it, but underhood when the <code>with</code> block ends it makes sure that the file is correctly closed, actually, if an exception happens while proccessing the file it also closes it properly. This isn't only used for context managers, you can use it for dealing with database connections and networking stuff.</p>"},{"location":"posts/context_managers_usage/#writting-context-managers","title":"Writting context managers","text":"<p>There two ways to write context mangers in Python, the first one is to write a Python class which implements the two dunder methods <code>__enter__</code> and <code>__exit__</code>, like so:</p> <pre><code>class MyContextManager:\ndef __init__(self, filename, mode)\nself.filename = filename\nself.mode = mode\ndef __enter__(self)\nself.file = open(self.filename, mode=self.mode)\nreturn self.file\ndef __exit__(self, exc_type, exc_value, exc_traceback)\nif self.file:\nself.file.close()\n</code></pre> <p>Another way to achieve the same thing is using the <code>contextlib</code>, like this: <pre><code>from contextlib import contextmanager\ndef my_context_manager(filename, mode):\nfile = open(filename, mode=mode)\ntry:\nyield file\nfinally:\nfile.closed()\n</code></pre></p> <p>The two previous implementations are doing similar things.</p>"},{"location":"posts/context_managers_usage/#other-useful-usages-of-context-managers","title":"Other useful usages of Context Managers.","text":""},{"location":"posts/context_managers_usage/#1-update-an-environment-variable-temporary","title":"1. Update an environment variable temporary","text":"<p>Imagine that you have a Python function which is using an environment variable to make some type of operation.</p> <pre><code>def use_env_variable(arg1, arg2, ...):\n# some code before\nvariable = os.environ.get('MY_VAR')\n# some code after which uses the environment variable `variable`\n...\n</code></pre> <p>But you realize that the environment variable doesn't have the right value before executing <code>use_env_variable</code> function, and also, that you cannot update <code>MY_VAR</code> because other functions depend on the old value of <code>MY_VAR</code>.</p> <p>A way to solve this problem woud be:</p> <ul> <li> <p>Before executing <code>use_env_variable</code>:</p> <ul> <li>Get the current value of environment variable and store it in a new variable</li> <li>Set the environment variable to new value</li> </ul> </li> <li> <p>Run <code>use_env_variable</code>:</p> <ul> <li>It uses the environment variable with the new value</li> </ul> </li> <li> <p>After executing <code>use_env_variable</code>:</p> <ul> <li>Use the old environment variable fetched before executing the function and set it to the environment variable again.</li> </ul> </li> <li> <p>Run more code.</p> </li> </ul> <p>In code this would be:</p> <pre><code>old_value = os.environ.get('MY_VAR')\nos.environ['MY_VAR'] = 'My new value'\nuse_env_variable(arg1, arg2, ..)\nos.environ['MY_VAR'] = old_value\n</code></pre> <p>The previous solution does its work, that's what we need. But now imagine that just like <code>use_env_variable</code>, there are other functions that also need to do the same things and other code needs to use the old value, we can continue using the previous solution but the code gets meessy. Here context mangers come in handy.</p> <p>To avoid using the previous solution, We can write a context manager which temporarily updates the environment variable. When entering the <code>with</code> block, the variable is set to a new value. Upon exiting, the variable is reverted to its original value.</p> <p>Let's code it:</p> Note <p>We'll write the context manager using the <code>contextlib</code> libray for the sake of simplicity.</p> <pre><code>from contextlib import contextmanager\n@contextmanager\ndef set_environ(var_name, new_value):\n\"\"\"Set a `new_value`` to the environment variable `var_name`\"\"\"\nold_value = os.environ.get(var_name)\nos.environ[var_name] = new_value\ntry:\nyield\nfinally:\nos.environ[var_name] = old_value\n</code></pre> <p>now, we can use our previous context manager in a <code>with</code> block to update an environment variable temporarly.</p> <pre><code>with set_environment('MY_VAR', 424):\n# use functions that depen on the new value of the environment variable\n...\nprint(os.environ.get('MY_VAR')) # it should print the old value, not 424.\n</code></pre> <p>it was clear and beatiful solution using context manager, isn't it ?</p>"},{"location":"posts/context_managers_usage/#2-timing-python-code","title":"2. Timing Python code","text":"<p>The second useful usage of a context manager is for timing how long a python piece of code takes to run.</p> <p>Imagine that you want to time how long some python functions in your code take to run, a solution would be to use the python <code>time</code> module, something like so:</p> <pre><code>import time\nstart = time.time()\nrun_function()\nelasep = time.time() - start\n</code></pre> <p>The previous solution works okay, but we could use a context manager to achieve the same thing in a fancy and reusable way. Let's code this by using the classic Context Manager.</p> <pre><code>import time\nclass Timer:\ndef __init__(self):\nself._start = None\nself._end = None\ndef __enter__(self):\nself._start = time.time()\ndef __exit__(self, exc_type, exc_value, exc_traceback):\nself._end = time.time()\nprint(f'it takes {self._end - self._start} to finish!')\n</code></pre> <p>We can use the above <code>Timer</code> context manager to measure the execution time of our functions. For example, to determine the runtime of a function called <code>square</code> that returns a list of squared integers, we'd use it as follows.</p> <pre><code>def square(array):\nreturn [num**2 for num in array]\nwith Timer():\nsquare([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n</code></pre> <p>After running the previous snippet we should see on the standard out the following:</p> <pre><code>it took 8.344650268554688e-06 to finish! # (1)\n</code></pre> <ol> <li>The time that this function took to run on your machine should be different.</li> </ol> <p>Look at how easy was to write a reausable context manager to time our python code. \ud83d\ude0e</p>"},{"location":"posts/python_event_loop/","title":"Keeping track of asyncio.run execution.","text":"<p>Have you ever been curious about the inner workings of the <code>asyncio.run()</code> function? If the answer is no, then get ready for a fascinating journey. This blog post will guide you through the process that takes place behind the scenes.</p>"},{"location":"posts/python_event_loop/#before-we-begin","title":"Before we begin.","text":"<p>We will be using as reference the <code>CPython 3.11.4</code> implementation. Please note that in earlier versions of CPython, the event loop might have been implemented differently. This is an important note because we will be looking at the CPython implementation to see step-by-step the execution proccess followed when <code>asyncio.run()</code> function is called.</p>"},{"location":"posts/python_event_loop/#asyncioruncoro-debugnone","title":"<code>asyncio.run(coro, *, debug=None)</code>","text":"<p><code>asyncio.run()</code> is used to run a coroutine in the event loop, it also creates a new event loop and closes it at the end. Allright, what's next ? well, things are getting insteresting here. Actually, <code>asyncio.run()</code> is shortcut for:</p> <pre><code>with asyncio.Runner(debug=True) as runner:\nrunner.run(main())\n</code></pre> <p>This means if we want to know what is happening when <code>asyncio.run()</code> is called we shoud go to the <code>Runner</code> class. Let's go there: \ud83d\ude40</p> Note <p>I've deleted some code, comments and documentation from the below class, just to make it shorter.</p> cpython/Lib/asyncio/runner.py<pre><code>class Runner:\ndef __init__(self, *, debug=None, loop_factory=None):\n...\nself._loop = None\n...\n...\ndef run(self, coro, *, context=None):\nif not coroutines.iscoroutine(coro):\nraise ValueError(\"a coroutine was expected, got {!r}\".format(coro))\nif events._get_running_loop() is not None:\nraise RuntimeError(\n\"Runner.run() cannot be called from a running event loop\")\nself._lazy_init()\nif context is None:\ncontext = self._context\ntask = self._loop.create_task(coro, context=context)\nif (threading.current_thread() is threading.main_thread()\nand signal.getsignal(signal.SIGINT) is signal.default_int_handler\n):\nsigint_handler = functools.partial(self._on_sigint, main_task=task)\ntry:\nsignal.signal(signal.SIGINT, sigint_handler)\nexcept ValueError:\nsigint_handler = None\nelse:\nsigint_handler = None\nself._interrupt_count = 0\ntry:\nreturn self._loop.run_until_complete(task)\nexcept exceptions.CancelledError:\nif self._interrupt_count &gt; 0:\nuncancel = getattr(task, \"uncancel\", None)\nif uncancel is not None and uncancel() == 0:\nraise KeyboardInterrupt()\nraise  # CancelledError\nfinally:\nif (sigint_handler is not None\nand signal.getsignal(signal.SIGINT) is sigint_handler\n):\nsignal.signal(signal.SIGINT, signal.default_int_handler)\ndef _lazy_init(self):\nif self._state is _State.CLOSED:\nraise RuntimeError(\"Runner is closed\")\nif self._state is _State.INITIALIZED:\nreturn\nif self._loop_factory is None:\nself._loop = events.new_event_loop()\nif not self._set_event_loop:\nevents.set_event_loop(self._loop)\nself._set_event_loop = True\nelse:\nself._loop = self._loop_factory()\nif self._debug is not None:\nself._loop.set_debug(self._debug)\nself._context = contextvars.copy_context()\nself._state = _State.INITIALIZED\n...\n</code></pre> <p>Yes, I know that is long class, but we're going to focus on <code>self.run()</code> &amp; <code>self._lazy_init()</code> methods. As we saw previously, when <code>asyncio.run</code> is exuceted actually we're creating an instance of <code>Runner</code> class and then we call its <code>run</code> instance method.</p> <p>When the <code>Runner</code> class instance is created some instance attributes are created as well, one of most important is <code>self._loop</code> which is set to <code>None</code>. Now when the instance is created we can call its <code>run</code> instance method, for that, we need to pass it a required argument <code>coro</code> which is coroutine that we want to run in the event loop. As we see in the <code>run</code> implementation (line 9) it starts making some validations, like:</p> <ol> <li>check if <code>coro</code> is actually a coroutine.    <pre><code> if not coroutines.iscoroutine(coro):\nraise ValueError(\"a coroutine was expected, got {!r}\".format(coro))\n</code></pre></li> <li>check if there is already an event loop running.    <pre><code> if events._get_running_loop() is not None:\nraise RuntimeError(\n\"Runner.run() cannot be called from a running event loop\")\n</code></pre></li> </ol> <p>if the previous checks pass succesfully, so the <code>self._lazy_init()</code> is called. This method also makes some checks but the most important here is the line 55:</p> <pre><code>self._loop = events.new_event_loop()\n</code></pre> <p>The above line creates the event loop and assigs it to the instance variable <code>self._loop</code>. Tracking the flow throught the code and assumming that <code>self._lazy_init()</code> ran successfully (line 17), we can skip some irrelevant lines of code and go to the line 21:</p> <pre><code>task = self._loop.create_task(coro, context=context)\n</code></pre> <p>it uses the previous created event loop and calls its <code>create_task</code> instance method for wrapping the <code>coro</code> passed to the <code>run</code> method into task.</p>"},{"location":"posts/python_event_loop/#digging-a-bit-into-self_loopcreate_task","title":"Digging a bit into <code>self._loop.create_task</code>","text":"<p>To know a bit about what's happening when <code>self._loop.create_task</code> is called, we need to go to <code>BaseEventLoop</code> class which we can find in the file base_events.py. Let's bring the class from there and take a look at it.</p> Note <p>I've deleted some code, comments and documentation from the below class, just to make it shorter.</p> <p>cpython/Lib/asyncio/base_events.py<pre><code>class BaseEventLoop(events.AbstractEventLoop):\n...\ndef create_task(self, coro, *, name=None, context=None):\nself._check_closed()\nif self._task_factory is None:\ntask = tasks.Task(coro, loop=self, name=name, context=context)\nif task._source_traceback:\ndel task._source_traceback[-1]\nelse:\nif context is None:\ntask = self._task_factory(self, coro)\nelse:\ntask = self._task_factory(self, coro, context=context)\ntasks._set_task_name(task, name)\nreturn task\n...\n</code></pre> The highlighted line shows that with the coroutine <code>coro</code> pass to the <code>self._loop.created_task</code> method an instance of <code>Task</code> is created with the same coroutine <code>coro</code> then, it's returned it at the end of BaseEventLoop's <code>create_task</code> method. With this in mind, we can return to the <code>run</code> execution.</p>"},{"location":"posts/python_event_loop/#run-coro-until-complete","title":"Run <code>coro</code> until complete.","text":"<p>After <code>coro</code> is wrapped into a <code>Task</code> (line 21), <code>run</code> makes some other types of validations and finally the task is passed to <code>run_until_complete</code> event loop instance method.</p> <p>The <code>run_until_complete</code> methods run the task passed as parameter until it's finished.</p>"},{"location":"posts/python_event_loop/#sum-up","title":"Sum up!","text":"<p>As you could see, there is nothing special underhood when the <code>asyncio.run()</code> function is run, it only created and instance of <code>Runner</code> class and then its <code>run</code> instance method is executed, when this happens, there are some other methods executed, like <code>create_task</code> and finally <code>run_until_complete</code>.</p>"},{"location":"posts/retries_with_requests/","title":"Retrying HTTP requests with Python requests library.","text":"<p>The Python <code>requests</code> library is among the most popular today. According to GitHub, 2.3 million users \ud83d\ude31 are using it. One of the primary reasons for its widespread adoption is its user-friendly API.</p> <p>By default, the requests made with the <code>requests</code> library are not \"retrying\", this means that once a request is sent and it fails for any reason (like network issues, server timeouts, or temporary outages), the library won't automatically attempt to send the request again.</p> <p>Sometimes we want to ensure reliable communication between systems. For example, in e-commerce platforms, when a customer places an order, it's essential that the order details are accurately communicated to inventory systems, payment gateways, and shipping providers. Any failure in these communications can result in missed shipments, incorrect billing, or overselling of inventory. In such critical scenarios, merely logging an error isn't enough; implementing retries becomes crucial to ensure that business operations run smoothly and customer trust is maintained.</p> <p>Implementing retries requires the use of certain strategies. We cannot retry a request immediately after it fails; we need to wait a specific period of time for the service/API to become available again. For this, several strategies exist that can be employed to optimize the retry mechanism. One of the most common is exponential backoff. This strategy involves increasing the waiting time between retries exponentially, so that each retry waits longer than the previous one. This allows the service or API sufficient time to recover from any transient issues or high traffic.</p>"},{"location":"posts/retries_with_requests/#how-can-requests-library-help-us-implement-retries","title":"How can <code>requests</code> library help us implement retries ?","text":"<p>The first thing to know is that the <code>requests</code> library is built on top of urllib3. This foundational library, urllib3, has built-in support for connection pooling and retries, which makes it a robust choice for web requests. Leveraging this underlying functionality, <code>requests</code> can be configured to implement retries with a big variety of features.</p> <p>To provide the retrying capabilities to <code>requests</code> we have to import the <code>Retry</code> class from <code>urllib3</code> library like this:</p> <pre><code>from urllib3.util import Retry # (1)!\n</code></pre> <ol> <li>If you installed <code>requests</code>, <code>urllib3</code> is already installed too.</li> </ol> <p>now, let's explore what attributes <code>Retry</code> class accepts:</p> Note <p>For a better description of <code>Retry</code> attributes, please go to https://urllib3.readthedocs.io/en/stable/reference/urllib3.util.html#urllib3.util.Retry. version <code>2.4.0</code></p> <pre><code>Retry(\ntotal=10,\nconnect=None,\nread=None,\nredirect=None,\nstatus=None,\nother=None,\nallowed_methods=frozenset({'DELETE', 'GET', 'HEAD', 'OPTIONS', 'PUT', 'TRACE'}),\nstatus_forcelist=None,\nbackoff_factor=0,\nbackoff_max=120,\nraise_on_redirect=True,\nraise_on_status=True,\nhistory=None,\nrespect_retry_after_header=True,\nremove_headers_on_redirect=frozenset({'Authorization'}),\nbackoff_jitter=0.0\n)\n</code></pre> <ol> <li>total (int): Total number of retries to allow.</li> <li>connect (int): How many connection-related errors to retry on.</li> <li>read (int): How many times to retry on read errors.</li> <li>redirect (int): How many redirects to perform. Limit this to avoid infinite redirect loops.</li> <li>status (int): How many times to retry after bad status codes.</li> <li>other (int): How many times to retry on other types of errors.</li> <li>allowed_methods (frozenset): Set of uppercased HTTP method verbs that we should retry on.</li> <li>status_forcelist (list): A set of integer HTTP status codes that we should force a retry on.</li> <li>backoff_factor (float): A backoff factor to apply between attempts. urllib3 will sleep for: <code>{backoff factor} * (2 **({number of previous retries}))</code> seconds. For instance, with <code>backoff_factor</code> set to <code>0.5</code>, the sleep times would be <code>[0s, 0.5s, 1s, 2s, 4s, \u2026]</code>.</li> <li>backoff_max (int): Maximum sleep time between retries.</li> <li>raise_on_redirect (bool): Whether or not to raise an error on redirects.</li> <li>raise_on_status (bool): Whether or not to raise an error on status.</li> <li>history (tuple): The history of the request encountered during each call to <code>increment()</code>.</li> <li>respect_retry_after_header (bool): Whether or not to respect the Retry-After header in responses.</li> <li>remove_headers_on_redirect (Collection): Sequence of headers to remove from the request when a response indicating a redirect is returned before firing off the redirected request.</li> <li>backoff_jitter (float): The amount of jitter (randomness) to apply to the delay time before the next retry, given as a fraction of the computed delay time.</li> </ol> <p>Now that we brought the <code>Retry</code> class from urllib3 and gained a foundational understanding of its attributes, it's time to integrate it with the <code>requests</code> library. To achieve this, we'll use the <code>Session</code> class from <code>requests</code> library. After creating a session, we can then attach our retry logic by mounting an adapter (<code>HTTPAdapter</code>) to it. Here's how it's done:</p> <pre><code>from urllib3.util import Retry\nfrom requests import Session # (1)!\nfrom requests.adapters import HTTPAdapter\nsession = Session()\nretries = Retry() # (2)!\nsession.mount('https://', HTTPAdapter(max_retries=retries)) # (3)!\n</code></pre> <ol> <li>The <code>requests</code> version used in this post is <code>2.31.0</code></li> <li>If we leave out the Retry's arguments, by default, it'll retry the requests 10 times inmediately in case of connection or read errors.</li> <li>If you want to make requests using the <code>http</code> protocol you need to mount another HTTPAdapter like this: <code>session.mount('http://', HTTPAdapter(max_retries=retries))</code>.</li> </ol> <p>The above code means that when we make an HTTP request using the <code>session</code> variable, it will have the retry logic we set up previously in the <code>Retry</code> class.</p>"},{"location":"posts/retries_with_requests/#retrying-in-case-of-gettting-status-codes","title":"Retrying in case of gettting status codes","text":"<p>Now consider a scenario where you're making an HTTP request to a service and you want to retry the request in case you get a 500(indicating server errors) and 503(often indicating service unavailability) status codes. For this case, you could set up a retry logic using <code>requests</code> like so:</p> <pre><code>from urllib3.util import Retry\nfrom urllib3 import add_stderr_logger\nfrom requests import Session\nfrom requests.adapters import HTTPAdapter\nadd_stderr_logger() # (1)!\nsession = Session()\nretries = Retry(\ntotal=None,\nconnect=False,\nread=False,\nstatus=3,\nbackoff_factor=1,\nstatus_forcelist=[503, 500],\n)\nsession.mount('https://', HTTPAdapter(max_retries=retries))\nresp = session.get(\"https://my_sevice_url.com\")\n</code></pre> <ol> <li>This function help us see the logs for each retry on the stderror.</li> </ol> <p>The above code initiates an HTTP GET request to <code>https://my_service_url.com</code>. If the server responds with a status code found in <code>status_forcelist</code>, the request will be retried 3 times. The wait times between retries follow this pattern: <code>[0s, 2s, 4s]</code>. However, the delay won't exceed the value specified in <code>backoff_max</code> (you can change this value if needed). If the server's response header includes the <code>Retry-After</code> key, its value will override the calculated wait time based on the backoff factor (You can disable this behaviour setting <code>respect_retry_after_header</code> to <code>False</code>). In the above retry logic, it's important to note that if we exhaust all retries, we will receive a <code>RetryError</code> exception. Additionally, if for any reason we receive a status code during a retry that's not in the list <code>status_forcelist</code> (e.g., 403), the retries will stop immediately, and we will encounter the exception associated with that specific status code.</p> Warning <p>You might be curious about why I set <code>connect</code> and <code>read</code> to <code>False</code>. The reason is that if these parameters are left at their default values, in the event of a connect or read error, the retries will be attempted indefinitely.I also set <code>total</code> to <code>None</code>, which causes the retry logic to fall back on the <code>read</code>, <code>connect</code>, or <code>status</code> counters.</p>"},{"location":"posts/retries_with_requests/#retry-http-post-method","title":"Retry HTTP POST method","text":"<p>By default, retryable HTTP methods include HEAD, GET, PUT, DELETE, OPTIONS, and TRACE. However, if you need to retry a POST request, you must update the <code>allowed_methods</code> parameter in the <code>Retry</code> configuration. See the example below for guidance.</p> <pre><code># ... previous imports\nsession = Session()\nretries = Retry(\ntotal=None,\nconnect=False,\nread=False,\nstatus=3,\nbackoff_factor=1,\nstatus_forcelist=[503, 500],\n)\nsession.mount('https://', HTTPAdapter(max_retries=retries))\nresp = session.post(\"https://my_service_url.com\", data={\"key\": \"value\"})\n# ... more code\n</code></pre> <p>You can include any HTTP methods of your choice and specify the status codes you wish to retry on.</p>"},{"location":"posts/retries_with_requests/#to-sum-up","title":"To Sum up!","text":"<p>As demonstrated, it's straightforward to implement retry logic for HTTP requests using the <code>requests</code> library. This is made possible by the <code>Retry</code> class from urllib3, which offers extensive configuration options. Experiment with parameters not covered in this post and see how they can fit into your use cases.</p> <p>Moreover, remember not to over-retry, as this can increase load on servers or even be perceived as a DDoS attack. Also, consider logging retries. When they occur, it's crucial for debugging.</p> <p>There are other retry libraries out there that you can use to implement retries for your requests, I will drop a list of some that I know:</p> <ol> <li>Backoff - https://github.com/litl/backoff</li> <li>Tenacity - https://github.com/jd/tenacity</li> <li>Stamina - https://github.com/hynek/stamina</li> </ol> <p>All of them use the decorator strategy and have some nice features that you can try.</p>"}]}